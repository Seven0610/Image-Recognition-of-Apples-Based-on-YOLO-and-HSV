{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "import torch.onnx\n",
    "import torch\n",
    "import random\n",
    "import time\n",
    "import shutil\n",
    "from vision.ssd.vgg_ssd import create_vgg_ssd\n",
    "from vision.ssd.mobilenetv1_ssd import create_mobilenetv1_ssd\n",
    "from vision.ssd.mobilenetv1_ssd_lite import create_mobilenetv1_ssd_lite\n",
    "from vision.ssd.squeezenet_ssd_lite import create_squeezenet_ssd_lite\n",
    "from vision.ssd.mobilenet_v2_ssd_lite import create_mobilenetv2_ssd_lite\n",
    "\n",
    "from vision.ssd.config import mobilenetv1_ssd_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the image file and sorted image storage address\n",
    "imagefile_path = r\"F:\\\\code\\\\detect_data\"\n",
    "# Save file address\n",
    "savefile_path = r\"F:\\\\code\\\\detect_data\\\\Annotations\"\n",
    "\n",
    "# Set the ratio of training set, verification set, and test set\n",
    "trainval_rate = 0.8 # Training verification set\n",
    "train_rate = 0.8 # training set\n",
    "\n",
    "\n",
    "# Read the image dataset\n",
    "total_images = os.listdir(imagefile_path)\n",
    "# Record the total number of current image datasets\n",
    "total_num = len(total_images)\n",
    "image_list = range(total_num)\n",
    "\n",
    "# Count the number of verification and test sets\n",
    "validation_set_num = int(total_num * trainval_rate) # Number of training validation sets\n",
    "train_set_num = int(validation_set_num * train_rate) # Number of training sets\n",
    "print(\"Validation set size:\", validation_set_num)\n",
    "print(\"Train set size:\", train_set_num)\n",
    " \n",
    " \n",
    "# Random sampling as training set, test set and verification set\n",
    "random.seed(1)  \n",
    "validation_sample = random.sample(image_list, validation_set_num) \n",
    "train_sample = random.sample(validation_sample, train_set_num)  \n",
    " \n",
    "# Data set partitioning\n",
    "start = time.time()\n",
    "test_num = 0 # test set\n",
    "train_num = 0 # training set\n",
    "val_num = 0 # Training verification set\n",
    " \n",
    "for i in image_list:\n",
    "    name = total_images[i]\n",
    "    if i in validation_sample:\n",
    "        if i in train_sample:\n",
    "            directory = \"train\"\n",
    "            train_num += 1\n",
    "            images_path = os.path.join(os.getcwd(), \"F:/code/detect_data/Annotations/{}\".format(directory))\n",
    "            if(not os.path.exists(images_path)):  \n",
    "                # If the folder indicated by directory does not exist, create it with the following command\n",
    "                os.mkdir(images_path)          \n",
    " \n",
    "            file_path = os.path.join(imagefile_path, name)  \n",
    "            newfile = os.path.join(savefile_path, os.path.join(directory,name))\n",
    "            shutil.copyfile(file_path, newfile)           \n",
    " \n",
    "        else:\n",
    "            directory = \"validation\"\n",
    "            images_path = os.path.join(os.getcwd(), \"F:/code/detect_data/Annotations/{}\".format(directory))\n",
    "            if(not os.path.exists(images_path)):\n",
    "                os.mkdir(images_path)                \n",
    " \n",
    "            val_num += 1\n",
    "            file_path = os.path.join(imagefile_path, name)\n",
    "            newfile = os.path.join(savefile_path, os.path.join(directory,name))\n",
    "            shutil.copyfile(file_path, newfile)\n",
    "           \n",
    "    else:\n",
    "        directory = \"test\"\n",
    "        images_path = os.path.join(os.getcwd(), \"F:/code/detect_data/Annotations/{}\".format(directory))\n",
    "        if(not os.path.exists(images_path)):\n",
    "            os.mkdir(images_path)\n",
    "        \n",
    "        test_num += 1 \n",
    "        file_path = os.path.join(imagefile_path, name)\n",
    "        newfile=os.path.join(savefile_path, os.path.join(directory,name))\n",
    "        shutil.copyfile(file_path, newfile)\n",
    "       \n",
    "end = time.time() \n",
    "finish = end-start\n",
    "print(\"Time taken:{0:.2f} seconds\".format(finish))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data set tag\n",
    "labelImg image annotation tool was used to carry out feature annotation for Apple images of training set, test set and verification set respectively.\n",
    "Create a VOC dataset\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quickly convert the generated.xml file into a.csv file in batches\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    " \n",
    "def xml_to_csv(path):  \n",
    "    xml_list = []  \n",
    "    for xml_file in glob.glob(path + '/*.xml'):  \n",
    "        tree = ET.parse(xml_file)  \n",
    "        root = tree.getroot()\n",
    "       \n",
    "        print(root.find('filename').text)  \n",
    "        for member in root.findall('object'): \n",
    "            value = (root.find('filename').text[:-4],  \n",
    "                int(root.find('size')[0].text),   #Width  \n",
    "                int(root.find('size')[1].text),   #Height  \n",
    "                member[0].text,   \n",
    "                int(member[4][0].text), \n",
    "                int(float(member[4][1].text)), \n",
    "                int(member[4][2].text),  \n",
    "                int(member[4][3].text)\n",
    "                )  \n",
    "            xml_list.append(value)\n",
    "    column_name = ['ImageID', 'width', 'height', 'ClassName', 'XMin', 'YMin', 'XMax', 'YMax']\n",
    "    xml_df = pd.DataFrame(xml_list, columns=column_name)  \n",
    "    return xml_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the following store() function can directly carry out the above method call and the generated file.csv file storage\n",
    "def store():\n",
    "    for directory in ['train','test','validation']:\n",
    "        xml_path = os.path.join(os.getcwd(), 'F:/code/detect_data/cooneo_xml/{}'.format(directory)) # Store.xml folder address\n",
    "        xml_df = xml_to_csv(xml_path)\n",
    "        xml_df.to_csv('F:/code/detect_data//Annotations/sub-{}-annotations-bbox.csv'.format(directory),\n",
    "                      index=None) \n",
    "        print(\"Successfully converted xml to csv.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function call implementation\n",
    "store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training\n",
    "\"\"\" Upload your own VOC dataset\n",
    "\n",
    "unzip address -d Address for storing the decompressed file\n",
    "unzip /content/drive/MyDrive/Cooneo/Apple-Rigeness/Annotations.zip -d  /content/drive/MyDrive/Cooneo/Apple-Rigeness/Apple-Rigeness\n",
    "\n",
    "# View the current GPU environment configuration\n",
    "nvidia-smi\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "Download pre-training models and training scripts\n",
    "wget https://nvidia.box.com/shared/static/djf5w54rjvpqocsiztzaandq1m3avr7c.pth -O  /content/drive/MyDrive/Cooneo/models/mobilenet-v1-ssd-mp-0_675.pth\n",
    "git clone https://github.com/dusty-nv/pytorch-ssd\n",
    "\n",
    "Model training\n",
    "# Train in a cloud environment\n",
    "/usr/bin/python3 /content/pytorch-ssd/train_ssd.py --data=/content/drive/MyDrive/Cooneo/Apple-R\n",
    "# Train in a local environment\n",
    "python3 train_ssd.py -data= data set storage address --model-dir= trained model storage address --batch-size=10 --epochs=100\n",
    "\n",
    "Model format conversion\n",
    "# In a cloud environment\n",
    "/usr/bin/python3 /content/pytorch-ssd/onnx_export.py  - input = / content/drive/MyDrive/Cooneo/Apple - Ripeness_model/mb1 - SSD - Epoch - 99 - Loss - 32774.71484375. PTH --model-dir=/content/drive/MyDrive/Cooneo/Apple-Ripeness_model\n",
    "# Run locally\n",
    "python3 model script address /onnx_export.py --input= Last trained model --model-dir= converted model storage address\n",
    "\n",
    "Maturity detection using onnx_export.py\n",
    "\"\" \""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
