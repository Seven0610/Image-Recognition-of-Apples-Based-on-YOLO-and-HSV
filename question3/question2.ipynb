{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a feature extracting kernel made for increasing accuracy\n",
    "def extraction (image):\n",
    "    Kernel  = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "    img_k = cv2.filter2D(image,-1, kern)\n",
    "    img = cv2.cvtColor(img_k, cv2.COLOR_BGR2HSV)\n",
    "    img[:,:,1] = 255\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_HSV2BGR)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Datasets\n",
    "\n",
    "datadir = r\"F:/code/detect_data\"\n",
    "# 1: High Rigeness: High rigeness\n",
    "# 2: Low Rigeness: Low rigeness\n",
    "# 3: Medium Rigeness: Medium rigeness\n",
    "# 4: represents a flower or flower (or no apple) : None\n",
    "Categories = ['1', '2', '3', '4']\n",
    "training_data = []\n",
    "test_images = ['Test']\n",
    "test_data = []\n",
    "def train ():\n",
    "\n",
    "    for category in Categories:\n",
    "        path = os.path.join(datadir, category)\n",
    "        class_num = Categories.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img))\n",
    "                img = cv2.cvtColor(img_array, cv2.COLOR_BGR2HSV)\n",
    "                img[:,:,1] = 255\n",
    "                \n",
    "                img_array = cv2.cvtColor(img, cv2.COLOR_HSV2BGR)\n",
    "                new_array = cv2.resize(img_array, (100, 100))\n",
    "                # here i changed flatten to reshaped (1, -1)\n",
    "                image = np.array(new_array).flatten()\n",
    "                # image = np.array(image).reshape(1,-1)\n",
    "                training_data.append([image, class_num])\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "def test ():\n",
    "    for category in test_images:\n",
    "        path = os.path.join(datadir, category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img))\n",
    "\n",
    "                img_hsv = cv2.cvtColor(img_array, cv2.COLOR_BGR2HSV)\n",
    "                img_hsv[:, :, 1] = 255\n",
    "                img_array = cv2.cvtColor(img_hsv, cv2.COLOR_HSV2BGR)\n",
    "                new_array = cv2.resize(img_array, (100, 100))\n",
    "                # here i changed flatten to reshaped (1, -1)\n",
    "                image = np.array(new_array).flatten()\n",
    "#                 image = np.array(image).reshape(1,-1)\n",
    "\n",
    "                test_data.append([image])\n",
    "            except:\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING DATA PREPARATION \n",
    "train()\n",
    "random.shuffle(training_data)\n",
    "print(len(training_data))\n",
    "with open('training_data.pkl', 'wb') as f:\n",
    "    pickle.dump(training_data,f)\n",
    "print ('Saved Successfully!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SPLITTING DATA INTO ATTRIBUTES AND LABELS ###\n",
    "\n",
    "with open('training_data.pkl', 'rb') as f:\n",
    "    training_data = pickle.load(f)\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for features, label in training_data:\n",
    "    x.append(features)\n",
    "    y.append(label)\n",
    "    \n",
    "\n",
    "\n",
    "with open('x.pkl', 'wb') as feat:\n",
    "    pickle.dump(x,feat)\n",
    "print ('Saved Attributes Successfully!')\n",
    "\n",
    "with open('y.pkl', 'wb') as lab:\n",
    "    pickle.dump(y,lab)\n",
    "print ('Saved labels Successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### LOADING Training dataset for splitting ####\n",
    "\n",
    "with open('x.pkl', 'rb')as feat:\n",
    "    X = pickle.load(feat)\n",
    "with open('y.pkl ', 'rb') as lab:\n",
    "    Y = pickle.load(lab)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### TRAINING Time bro ###\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size=0.25)\n",
    "\n",
    "\n",
    "# xtrain = sc.fit_transform(xtrain)\n",
    "# xtest = sc.transform(xtest)\n",
    "\n",
    "model = SVC(C=1 , kernel = 'linear', gamma='auto')\n",
    "# model = CalibratedClassifierCV(model)\n",
    "model.fit(xtrain, ytrain)\n",
    "\n",
    "Accuracy = model.score(xtest, ytest)\n",
    "overfit = model.score(xtrain, ytrain)\n",
    "predictions = model.predict(xtest)\n",
    "print ('Accuracy: ', Accuracy)\n",
    "print ('Overfit: ', overfit)\n",
    "print(classification_report(ytest, predictions ))\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(ytest, predictions)\n",
    "print (cm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn . ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg = BaggingClassifier(SVC(C=1 , kernel = 'linear', gamma='auto', probability = True), max_samples = 1.0 , max_features = 1.0, n_estimators = 30, oob_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg.fit(xtrain , ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bg.score (xtest, ytest))\n",
    "bg.predict(xtest)\n",
    "overfit = bg.score(xtrain, ytrain)\n",
    "predictions = bg.predict(xtest)\n",
    "# print ('Accuracy: ', Accuracy)\n",
    "print ('Overfit: ', overfit)\n",
    "print(classification_report(ytest, predictions ))\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(ytest, predictions)\n",
    "print (cm)\n",
    "# print(bg.score (xtrain, ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assessing the model\n",
    "clf = cross_val_score(bg, X, Y, cv = 10)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = cross_val_score(model, X, Y, cv = 10)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt = DecisionTreeClassifier(max_depth = 2)\n",
    "# dt.fit(xtrain, ytrain)\n",
    "# dt.score(xtrain, ytrain)\n",
    "rf = RandomForestClassifier(n_estimators = 11)\n",
    "rf.fit(xtrain, ytrain)\n",
    "rf.score(xtest, ytest)\n",
    "# rf.score(xtrain, ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.score(xtest , ytest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [{'C': [1,1.1,1.5, 2,10 ],'gamma': ['scalar', 'auto'],'kernel': ['linear','poly'] }, \n",
    "                {'C': [1,1.1,1.5, 2, 10 ],'gamma': [0.1,0.2,0.3,0.4, 0.5, 1 ],'kernel': ['rbf']}, ]\n",
    "\n",
    "gridsearch = GridSearchCV(estimator = model, param_grid= parameters, scoring = 'accuracy', cv = 10, n_jobs = 2)\n",
    "gridsearch = gridsearch.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gridsearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saving the damn model ###\n",
    "with open('Banana.pkl', 'wb') as mod:\n",
    "    pickle.dump(bg, mod)\n",
    "print (f'Saved pineapple Successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing images to confirm stuff, i.e importing the image directly ###\n",
    "img = cv2.imread('1.jpg')\n",
    "img = cv2.resize(img, (100,100))\n",
    "img = np.array(img).reshape(1,-1)\n",
    "\n",
    "cv2.imshow('test',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
